# Car_plate_detection_by_darknet_yoloV3

This project got it's inspiration to proceed with because of one ceo of startup who was about to offer me intern role... This only gave a push to me to explore number of resources get into in-depth knowledge of image processing, object detection and exploring difference between two.
I'm really thankful to him for letting me explore my limits to such an extent.
Mostly such type of projects take about 6 months for a novice.
Afterall these projects require in depth rnd and to choose which model suits best to proceed with.
This same happened for me...
But it took me 15 days of rnd and 5 days for execution.
I would have finished this project in 1 week but it took me more than 2 weeks.

- Journey started with in-depth study of image processing.
- Explored blogs, github repos, asked in communities at slack, Facebook groups, telegram groups, read research papers,
- Asked my seniors who were into machine learning, asked people on LinkedIn.

Then after selecting two blogs and corresponding two github repo ,I in-depth studied image processing but further I thought I was about to make a computer vision model but not simply write a code to detect that image.It also have me a thought to further check into for words being written there which could be further classified that to which country it belonged

## Tools could be used:
- Then I explored which language I could use: **MATLAB** or **python**
- Another take was on which library I need to choose **tensorflow** , **keras** , **scikit-learn** , **pytorch**
- How to image could be processed: **using opencv**
- Frameworks could be used: **darknet** , **darkflow(tensorflow version of darknet)** ,**LPRNet** , **Tesseract**
- if wanna go directly with an API then it's : **GoogleVision**

I would have provide a lot blogs which corresponds to above tools which I first try to implement and then got on my final product but
I think it's better to proceed with what I used in final product ðŸ˜Œ

Final product is made using **darknet** framework, **yolov3** weights and used **google colab** so that it could use cloud's hardware for processing and cloud's storage for storing the dataset using it as **IaaS** and **Sar**

## Some more explanation related to tools

### Core Framework and Tools

- **Python** is a very popular high-level programming language that is great for data science. Its ease of use and wide support within popular machine learning platforms, coupled with a large catalog of ML libraries, has made it a leader in this space.
- **Pandas** is an open-source Python library designed for analyzing and manipulating data. It is particularly good for working with tabular data and time-series data.
- **NumPy**, like Pandas, is a Python library. NumPy provides support for large, multi-dimensional arrays of data, and has many high-level mathematical functions that can be used to perform operations on these arrays.

### Machine Learning and Deep Learning
 
 - **Scikit-Learn** is a Python library designed specifically for machine learning. It is designed to be integrated with other scientific and data-analysis libraries, such as **NumPy**, **SciPy**, and **matplotlib**.
- **Apache Spark** is an open-source analytics engine that is designed for cluster-computing and that is often used for large-scale data processing and big data.
- **TensorFlow** is a free, open-source software library for machine learning built by Google Brain.
- **Keras** is a Python deep-learning library. It provide an Application Programming Interface (API) that can be used to interface with other libraries, such as TensorFlow, in order to program neural networks. Keras is designed for rapid development and experimentation.
- **PyTorch** is an open source library for machine learning, developed in large part by Facebook's AI Research lab. It is known for being comparatively easy to use, especially for developers already familiar with Python and a Pythonic code style.

## CNN workflow (To write)

## YoloV3 functioning:

Selects box with highest probability from all boxed objects.

### Architecture: 
### Epoch:
### Accuracy :
### Activation function: 

### How deep you know:
Technical Aspect
### How well you know:
Business Aspect

# **Prerequisites**

Nothing much required before if you are directly running Google colab notebook
Just need to run all the cells


## **Google Colab Notebooks**

## For environment set up( installation notebook):
https://colab.research.google.com/drive/1G-gC0JQutALKQNyYDBgkjKuDD-qQuDni?usp=sharing

</br>

## For Model training (training notebook) :
https://colab.research.google.com/drive/12qd5flRvELrnXsM_T_WM8yO_NtRqJIXS?usp=sharing

</br>

## For using the model over example image( demo notebook):
https://colab.research.google.com/drive/1j8N7boMiNM65YiSqVRXpnJ_nALi3_Neo?usp=sharing

</br>

## **Resources used**

## Link for dataset:
- http://www.zemris.fer.hr/projects/LicensePlates/english/  (used here) </br>
- https://datasetsearch.research.google.com/

## link for labelling dataset:

- https://github.com/tzutalin/labelImg (used here) </br>
- https://github.com/EscVM/OIDv4_ToolKit </br>
- https://github.com/theAIGuysCode/OIDv4_ToolKit </br>

- *Have used instructions as per above two repos only. Later one only provide with a command at top to provide final output of dataset.*
- *Further dataset has been directly uploaded to google drive for training the model*
- *Got error with AWS Client while fetching images as per these repos and had solved that by upgrading.*

## References
- https://colab.research.google.com/drive/1lTGZsfMaGUpBG4inDIQwIJVW476ibXk_#scrollTo=jAN2TNZ007c_ </br>
- https://colab.research.google.com/drive/1Mh2HP_Mfxoao6qNFbhfV3u28tG8jAVGk#scrollTo=VHw00Cro8ONr  </br>

## File Repo Reference
- https://github.com/theAIGuysCode/YOLOv3-Cloud-Tutorial/tree/master/yolov3   </br>
- https://github.com/theAIGuysCode/YOLOv3-Cloud-Tutorial                       </br>
- https://blog.francium.tech/custom-object-training-and-detection-with-yolov3-darknet-and-opencv-41542f2ff44e


## Presentation Website
https://komal7209.github.io/project-presentation-website/
